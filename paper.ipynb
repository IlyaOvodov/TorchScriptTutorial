{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как подружить PyTorch и C++. Используем TorchScript."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Около года назад разработчики PyTorch представили сообществу **TorchScript** - инструмент, который позволяет с помощью пары строк кода и нескольких щелчков мыши сделать из пайплайна на питоне отчуждаемое решение, которое можно встроить в систему на  C++. Ниже я делюсь опытом его использования и постараюсь описать встречающиеся на этом пути подводные камни. Особенное внимание уделю реализации проекта на Windows, поскольку, хотя исследования в ML обычное делается на Ubuntu, конечное решение часто (внезапно!) требуется под \"окошками\". \n",
    "\n",
    "Примеры кода для экспорта модели и проекта на C++, использующего модель, можно найти в [репозиториии на GitHub](https://github.com/IlyaOvodov/TorchScriptTutorial).\n",
    "\n",
    "![](https://github.com/IlyaOvodov/TorchScriptTutorial/blob/master/pics/BoxPT2.jpg?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разработчики PyTorch не обманули. Новый инструмент действительно позволяет превратить исследовательский проект на PyTorch в код, встраиваемый в систему на С++, за пару рабочих дней, а при некотором навыке и быстрее.\n",
    "\n",
    "TorchScript появился в PyTorch версии 1.0  и продолжает развиваться и меняться. Если первая версия годичной давности была полна багов и являлась скорее экспериментальной, то актуальная версия на данный момент версия 1.3 как минимум \n",
    "по второму пункту заметно отличается: экспериментальной ее уже не назовешь, она вполне пригодна для практического использования. Я буду ориентироваться на нее.\n",
    "\n",
    "В основе TorchScript лежит собственный автономный (не требующий наличия python) компилятор питон-подобного языка, а также средства для конвертации в него программы, написанной на python и PyTorch, методы сохранения и загрузки получившихся модулей и библиотека для их использования в C++. Для работы придется добавить в проект несколько DLL общим весом около 70MB (для Windows) для работы на CPU и 300MB для GPU версии. TorchScript поддерживает большинство функций PyTorch и основные возможности языка python. А вот о сторонних библиотеках, таких как OpenCV или NumPy, придется забыть. К счастью, у многих функций из NumPy есть аналог в pytorch.\n",
    "\n",
    "## Конвертируем пайплайн на PyTorch модель на TorchScript\n",
    "\n",
    "TorchScript предлагает два способа преобразования кода на python в его внутренний формат: tracing и scripting (трассировка и скриптование). Зачем два? Нет, понятно, конечно, что два лучше чем один...\n",
    "\n",
    "![](https://github.com/IlyaOvodov/TorchScriptTutorial/blob/master/pics/4em-boljshe-sdadim-tem-lu4she.jpg?raw=true)\n",
    "\n",
    "Но в случае с этими методами получается как в известном афоризме про левый и правый уклон: оба хуже. Что ж, мир несовершенен. Просто в конкретной ситуации надо выбирать тот, который больше подходит.\n",
    "\n",
    "Метод трассировки очень прост. Берется некий образец данных (обычно инициализированный случайными числами), отправляется в интересующую нас функцию или метод класса и PyTorch строит и запоминает граф вычислений примерно так же,\n",
    "как делает это обычно при обучении нейросети. Вуаля - скрипт готов: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "model = torchvision.models.resnet34(pretrained = True)\n",
    "model.eval()\n",
    "sample = torch.rand(1, 3, 224, 224)\n",
    "scripted_model = torch.jit.trace(model, sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В примере выше получается объект класса ScriptModule. Его можно сохранить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted_model.save('my_script.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "и загрузить потом в [программу на C++](https://github.com/IlyaOvodov/TorchScriptTutorial/tree/master/cpp_proj) (об этом [ниже](#cpp)) или в код на python вместо исходного объекта:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "transforms = Compose([ToTensor(), Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "img = cv2.resize(cv2.imread('pics/cat.jpg'), (224,224))\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "x = transforms(img).unsqueeze(0) # add batch dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripted_model = torch.jit.load('my_script.pth')\n",
    "y = scripted_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(282) tensor(12.8130, grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(y[0].argmax(), y[0][y[0].argmax()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получающийся объект `ScriptModule` может выступать везде, где обычно используется `nn.Module`.\n",
    "\n",
    "Описанным способом можно трассировать экземпляры класса `nn.Module` и функции (в последнем случае получается экземпляр класса `torch._C.Function`).\n",
    "\n",
    "Этот метод (tracing) имеет важное преимущество: так можно конвертировать почти любой питоновский код, не использующий внешних библиотек. Но есть и не менее важный недостаток: при любых ветвлениях будет запомнена только та ветка, которая исполнялась на тестовых данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniconda3\\lib\\site-packages\\ipykernel_launcher.py:2: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1) tensor(-1)\n"
     ]
    }
   ],
   "source": [
    "def my_abs(x):\n",
    "    if x.max() >= 0:\n",
    "        return x\n",
    "    else:\n",
    "        return -x\n",
    "my_abs_traced = torch.jit.trace(my_abs, torch.tensor(0))\n",
    "print(my_abs_traced(torch.tensor(1)), my_abs_traced(torch.tensor(-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Упс! Кажется, это не то, что мы хотели бы, правда? Хорошо, что по этому поводу хотя бы выдаётся предупреждающее сообщение (TracerWarning) Относитесь к таким сообщениям внимательно.\n",
    "\n",
    "Тут нам на помощь приходит второй метод - scripting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1) tensor(1)\n"
     ]
    }
   ],
   "source": [
    "my_abs_script = torch.jit.script(my_abs)\n",
    "print(my_abs_script(torch.tensor(1)), my_abs_script(torch.tensor(-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ура, ожидаемый результат получен! Scripting рекурсивно анализирует код на python и преобразует в код на собственном языке. На выходе получаем тот же класс `ScriptModule` (для модулей) или `torch._C.Functio`(для функций) . Казалось бы, счастье есть! Но возникает другая проблема: внутренний язык TorchScript строго типизированный, в отличие от python. Тип каждой переменной определяется первым присваиванием, тип аргументов функции по умолчанию - `Tensor`. Поэтому, например, привычный шаблон "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func(x):\n",
    "    y = None\n",
    "    if x.max() > 0:\n",
    "        y = x\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "оттрассировать не удастся:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "\nVariable 'y' previously has type None but is now being assigned to a value of type Tensor\n:\nat <ipython-input-8-75677614fca6>:4:8\ndef my_func(x):\n    y = None\n    if x.max() > 0:\n        y = x\n        ~ <--- HERE\n    return y\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-25414183a687>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmy_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscript\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\programming\\3rd_party\\pytorch\\pytorch_ovod_1.3.0a0_de394b6\\torch\\jit\\__init__.py\u001b[0m in \u001b[0;36mscript\u001b[1;34m(obj, optimize, _frames_up, _rcb)\u001b[0m\n\u001b[0;32m   1224\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_rcb\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1225\u001b[0m             \u001b[0m_rcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_gen_rcb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_frames_up\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1226\u001b[1;33m         \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_script_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqualified_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mast\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_rcb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_default_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1227\u001b[0m         \u001b[1;31m# Forward docstrings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1228\u001b[0m         \u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: \nVariable 'y' previously has type None but is now being assigned to a value of type Tensor\n:\nat <ipython-input-8-75677614fca6>:4:8\ndef my_func(x):\n    y = None\n    if x.max() > 0:\n        y = x\n        ~ <--- HERE\n    return y\n"
     ]
    }
   ],
   "source": [
    "my_func = torch.jit.script(my_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Даже точки после констант начинают играть роль:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "bool value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-0a5f18586763>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmy_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscript\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\programming\\3rd_party\\pytorch\\pytorch_ovod_1.3.0a0_de394b6\\torch\\jit\\__init__.py\u001b[0m in \u001b[0;36mscript\u001b[1;34m(obj, optimize, _frames_up, _rcb)\u001b[0m\n\u001b[0;32m   1224\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_rcb\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1225\u001b[0m             \u001b[0m_rcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_gen_rcb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_frames_up\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1226\u001b[1;33m         \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_script_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mqualified_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mast\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_rcb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_default_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1227\u001b[0m         \u001b[1;31m# Forward docstrings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1228\u001b[0m         \u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\programming\\3rd_party\\pytorch\\pytorch_ovod_1.3.0a0_de394b6\\torch\\jit\\__init__.py\u001b[0m in \u001b[0;36m_rcb\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m   1240\u001b[0m         \u001b[1;31m# closure rcb fails\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclosure_rcb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1242\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1243\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1244\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstack_rcb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: bool value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "def my_func(x):\n",
    "    if x.max() > 0:\n",
    "        y = 1.25\n",
    "    else:\n",
    "        y = 0\n",
    "    return y\n",
    "my_func = torch.jit.script(my_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Потому что надо писать не `0`, а `0.`, чтобы тип в обеих ветках был одинаковым! Избаловались, понимаешь, со своим питоном!\n",
    "\n",
    "Это только начало списка тех изменений, которые требуется внести в код на python, чтобы его можно было успешно превратить в модуль TorchScript. Более подробно самые типичные случаи перечислю [чуть позже](#tips). В принципе, никакой rocket science тут нет и свой код вполне можно поправить соответствующим образом. А вот исправлять сторонние модули, включая стандартные из `torchvision`, чаще всего править не хочется, а \"как есть\" для скриптования они обычно не пригодны.\n",
    "\n",
    "К счастью, обе технологии можно совмещать: то, что скриптуется - скриптовать, а что не скриптуется - трассировать:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModule, self).__init__()\n",
    "        self.resnet = torchvision.models.resnet34(pretrained = True)\n",
    "        # без следующих двух строк попытка сделать torch.jit.script(my_module) ниже выдаст ошибку \n",
    "        # где-то в недрах resnet34. Поэтому заблаговременно сами заменим self.resnet на ScriptModule.\n",
    "        self.resnet.eval() # NB: это надо сделать до трассировки! После трассировки не сработает!\n",
    "        self.resnet = torch.jit.trace(self.resnet, torch.rand((1,3,224,224), dtype=torch.float))\n",
    "    def forward(self, x):\n",
    "        if x.shape[2] < 224 or x.shape[3] < 224:\n",
    "            return torch.tensor(0)\n",
    "        else:\n",
    "            return self.resnet(x)\n",
    "my_module = MyModule()\n",
    "my_module = torch.jit.script(my_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В примере выше трассировка используется, чтобы включить модуль, не поддающийся скриптованию, в модуль, где недостаточно трассировки и необходимо скриптование. Бывает и обратная ситуация. Например, если нам надо выгрузить модель в ONNX, при этом используется трассировка. Но трассируемая модель может включать функции на TorchScript, поэтому логику, требующую ветвлений и циклов, можно реализовать там! Пример приведен в [официальной документации по torch.onnx](https://pytorch.org/docs/stable/onnx.html).\n",
    "\n",
    "Более подробно возможности, предоставляемые PyTorch для создания модулей на TorchScript описаны в [официальной документации](https://pytorch.org/docs/stable/jit.html) и [руководстве](https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html) по `torch.jit`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Включаем модель в проект на C++\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "К сожалению, [официальная документация](https://pytorch.org/tutorials/advanced/cpp_export.html) ограничивается примерами вида \"сложить 2 тензора, сгенерированных с помощью `torch.ones`\".\n",
    "Я подготовил [пример проекта](https://github.com/IlyaOvodov/TorchScriptTutorial/tree/master/cpp_proj), отправляющего в нейросеть картинку из OpenCV и получающего обратно результаты в виде тензора откликов, кортежа переменных, картинки с результатами сегментации.\n",
    "\n",
    "Для работы примера потребуются сохраненные скрипты классификации c помощью ResNet34 и сегментации с помощью DeepLabV3. Для подготовки этих скриптов надо запустить [этот jupyter блокнот](https://github.com/IlyaOvodov/TorchScriptTutorial/blob/master/prepare_scripts.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам потребуется библиотека `torchlib`. Получить ее можно несколькими путями:\n",
    "1. Если у вас уже стоит PyTorch, поставленный с помощью `pip install`, то ее можно найти в каталоге Python: `<Miniconda3>\\Lib\\site-packages\\torch`;\n",
    "2. Если у вас PyTorch собран из исходников, то она там: `<My Pytorch repo>\\build\\lib.win-amd64-3.6\\torch`;\n",
    "3. Наконец, можно скачать с [pytorch.org](https://pytorch.org) отдельно библиотеку, выбрав Language = C++, и распаковать архив."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код на C++ достаточно прост. Надо:\n",
    "1. Включить заголовочный файл\n",
    "```C++\n",
    "#include <torch/script.h>\n",
    "```\n",
    "2. Загрузить модель\n",
    "```C++\n",
    "torch::jit::script::Module module = torch::jit::load(\"../resnet34_infer.pth\");\n",
    "```\n",
    "3. Подготовить данные\n",
    "```C++\n",
    "torch::Tensor tensor_img = torch::from_blob(img.data, { img.rows, img.cols, 3 }, torch::kByte);\n",
    "```\n",
    "4. Вызвать фунцию `forward` и получить результат\n",
    "```C++\n",
    "auto output = module.forward( { tensor_img } )\n",
    "```\n",
    "5. Получить данные из результата. Как это сделать, зависит от того, что возвращает нейросеть. Кстати, принимать она в общем случае может тоже не только одну картинку, поэтому лучше посмотреть [на исходный код примера](https://github.com/IlyaOvodov/TorchScriptTutorial/blob/master/cpp_proj/cpp_proj.cpp) целиком, там присутствуют разные варианты. Например, для получения данных из одномерного тензора типа float:\n",
    "```C++\n",
    "float* data = static_cast<float*>(output.toTensor().data_ptr());\n",
    "```\n",
    "6. Есть еще одна тонкость. Не забыть вставить в код аналог `with torch.no_grad()`, чтобы не тратить ресурсы на вычисление и хранение\n",
    "не нужных нам градиентов. К сожалению, эту команду нельзя включить в скрипт, поэтому приходится добавлять в код на С++:\n",
    "```C++\n",
    "torch::NoGradGuard no_grad;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как собрать проект с помощью CMake, описано в [официальном руководстве](https://pytorch.org/tutorials/advanced/cpp_export.html). А вот тема проекта на Visual Studio там не раскрыта, поэтому опишу это подробнее. Придется вручную подкрутить настройки проекта:\n",
    "1. Я тестировал на Visual Studio 2017. Про другие версии сказать не могу\n",
    "1. Должна быть установлена v14.11 тулсета v141 (галочка `VC++ 2017 version 15.4 v14.11 toolset` в инсталляторе VS)\n",
    "1. Платформа должна быть x64\n",
    "1. В `General → Platform Toolset` выбрать `v141(Visual Studio 2017)`\n",
    "2. В `C/C++ → General → Additional Include Directories` добавить `libtorch dir\\include`\n",
    "3. В `Linker → General → Additional Library Directories` добавить `libtorch dir\\lib`\n",
    "4. В `Linker → Input → Additional Dependencies` добавить `torch.lib; c10.lib`. Пишут, что еще может потребоваться `caffe2.lib`, а для GPU и еще что-нибудь, но в текущей версии достаточно этих двух библиотек.\n",
    "5. Пишут также, что надо ставить `C/C++ → Language → Conformance Mode` = `No`, но я не увидел разницы.\n",
    "\n",
    "Также в проекте не должна быть объявлена переменная `__cplusplus`. Попытка добавить опцию компилятора [`/Zc:__cplusplus`](https://docs.microsoft.com/ru-ru/cpp/build/reference/zc-cplusplus?view=vs-2017) приведет к ошибкам при компиляции в файле `ivalue.h`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В [прилагаемом проекте](https://github.com/IlyaOvodov/TorchScriptTutorial/tree/master/cpp_proj) настройки путей (не только к TorchLib, но и к OpenCV и CUDA) вынесены в [props файл](https://github.com/IlyaOvodov/TorchScriptTutorial/blob/master/cpp_proj/cpp_proj.props), перед сборкой надо прописать их там в соответствии с вашей локальной конфигурацией. Вот, собственно, и все."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Что ещё следует иметь в виду"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если описанный процесс показался вам слишком простым, интуиция вас не обманула. Есть целый ряд нюансов, которые надо учитывать, чтобы преобразовать модель на PyTorch, написанную на python, в TorchScript. Перечислю ниже те, с которыми приходилось сталкиваться. Некоторые я уже упоминал, но повторюсь, чтобы собрать все в одном месте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/IlyaOvodov/TorchScriptTutorial/blob/master/pics/MinesweeperMario.jpg?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Типом переменных, передаваемых в функцию, по умолчанию считается Tensor. Если в каких-то (весьма частых) случаях это окажется неприемлемым, придется объявить типы вручную, используя MyPy-style type annotations, примерно так:\n",
    "```python\n",
    "def calc_letter_statistics(self, cls_preds, cls_thresh: float)->Tuple[int, Tuple[Tensor, Tensor, Tensor]]\n",
    "```\n",
    "или так: \n",
    "```python\n",
    "def calc_letter_statistics(self, cls_preds, cls_thresh):\n",
    "    # type: (List[Tensor], float)->Tuple[int, Tuple[Tensor, Tensor, Tensor]]\n",
    "```\n",
    "\n",
    "*  Переменные строго типизированы и тип, если не указан явно, определяется первым присваиванием. Привычные конструкции вида `x=[] ... for ...  x.append(y)` придется отредактировать, т.к. в момент присваивания `[]` компилятор не может понять, какой тип будет в списке. Поэтому придется указать тип явно, например:\n",
    "```python\n",
    "from typing import List\n",
    "x: List[float] = []\n",
    "```\n",
    "или (другое \"например\")\n",
    "```python\n",
    "from torch import Tensor\n",
    "from typing import Dict, Tuple, List\n",
    "x: Dict[int: Tuple[float, List[Tensor], List[List[int]]]] = {}\n",
    "```\n",
    "\n",
    "* В примере выше надо импортировать именно имена, поскольку эти имена зашиты в код TorchScript. Альтернативный вариант наименования\n",
    "```python\n",
    "import torch\n",
    "import typing\n",
    "x: typing.List[torch.Tensor] = []\n",
    "```\n",
    "приведет при скриптовании к ошибке *Unknown type constructor typing.List*\n",
    "\n",
    "* Еще одна привычная конструкция, с которой придется расстаться:\n",
    "```python\n",
    "x = None\n",
    "if smth:\n",
    "    x = torch.tensor([1,2,3])\n",
    "```\n",
    "Тут есть два варианта. Или оба раз присваивать Tensor (то, что он разной размерности, не страшно):\n",
    "```python\n",
    "x = torch.tensor(0)\n",
    "if smth:\n",
    "    x = torch.tensor([1,2,3])\n",
    "```\n",
    "и не забыть поискать, что сломается после такой замены. Или попытаться честно написать:\n",
    "```python\n",
    "x: Optional[Tensor] = None\n",
    "if smth:\n",
    "    x = torch.tensor([1,2,3])\n",
    "```\n",
    "но тогда при дальнейшем использовании `x` там, где ожидается тензор, мы, скорее всего, получим ошибку: *Expected a value of type 'Tensor' for argument 'x' but instead found type 'Optional[Tensor]'.*\n",
    "\n",
    "* Не забываем при первом присваивании писать, например, `x=0.` вместо привычного `x=0` и т.п., если переменная x должна иметь тип float.\n",
    "\n",
    "* Если где-то использовалась старомодная инициализация тензора через ```x = torch.Tensor(...)```, с ней придется расстаться и заменить на более молодежный вариант ```x = torch.tensor(...)```. Иначе при скриптовании прилетит: *Unknown builtin op: aten::Tensor. Here are some suggestions: aten::tensor*. Вроде бы, даже объясняют, в чем  проблема и понятно, что надо делать. Впрочем, понятно, если уже знаешь правильный ответ.\n",
    "\n",
    "* Код скриптуется в контексте того модуля, где вызван `torch.jit.script`. Поэтому если где-то в недрах скриптуемого класса или функции используется, например, `math.pow`, придется в компилирующий модуль добавить`import math`. А лучше скриптовать там же, где он объявлен: или с помощью декоратора `@torch.jit.script`, или объявив дополнительную функцию. Иначе получим сообщение об ошибке *undefined value math* при попытке скомпилировать модуль, в котором, казалось бы, сделан импорт `math`.\n",
    "\n",
    "* Если где-то у вас есть конструкция вида `my_tensor[my_tensor < 10] = 0` или подобная, то при скриптовании вы получите загадочную ошибку:\n",
    "```\n",
    "*aten::index_put_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False) -> (Tensor(a!)):*  \n",
    "*Expected a value of type 'Tensor' for argument 'values' but instead found type 'int'.*  \n",
    "*aten::index_put_(Tensor(a!) self, Tensor[] indices, Tensor values, bool accumulate=False) -> (Tensor(a!)):*  \n",
    "*Expected a value of type 'List[Tensor]' for argument 'indices' but instead found type 'List[Optional[Tensor]]'.*  \n",
    "```\n",
    "Что вам нужно - это заменить число на тензор: `my_tensor[my_tensor < 10] = torch.tensor(0.).to(my_tensor.device)`. Причем не забудьте а) про соответствие типов `my_tensor` и создаваемого тензора (в данном случае - float) и б) про `.to(my_tensor.device)`. Если забудете второе, все отскриптуется, но уже в процессе выполнения при работе на GPU вас ожидает огорчение, которое будет выглядеть как загадочные слова *CUDA error: an illegal memory access was encountered*, причем без указания на место возникновения ошибки!\n",
    "\n",
    "* Не забыть, что по умолчанию `nn.Module` и, соответственно, модели из torchvision создаются в  \"в режиме поезда\" (вы не поверите, но оказывается, [есть такой режим](https://fooobar.com/questions/16769103/error-when-converting-pytorch-model-to-torchscript/25666033#25666033)). При этом используется Dropout и т.п., что или сломает трассировку, или приведет к неадекватным результатам при выполнении. Не забудьте вызвать `model.eval()` перед скриптованием или трассировкой.\n",
    "\n",
    "* Для обычных классов надо скриптовать тип, для nn.Module - экземпляр\n",
    "\n",
    "* Попытка в методе скриптуемого метода обратиться к глобальной переменной\n",
    "```python\n",
    "cls_thresh = 0.3\n",
    "class MyModule(torch.nn.Module):\n",
    "    ...\n",
    "    x = r < cls_thresh\n",
    "    ...\n",
    "```\n",
    "приведет при скриптовании к ошибке вида  *python value of type 'float' cannot be used as a value*. Надо сделать переменную атрибутом в конструкторе:\n",
    "```python\n",
    "cls_thresh = 0.3\n",
    "class MyModule(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        ...\n",
    "        self.cls_thresh = cls_thresh\n",
    "    ...\n",
    "    x = r < self.cls_thresh\n",
    "    ...\n",
    "```\n",
    "\n",
    "* Еще одна тонкость возникает, если атрибут класса используется в качестве параметра среза:\n",
    "```python\n",
    "class FPN(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_layers =5):\n",
    "        ...\n",
    "        self.num_layers = num_layers\n",
    "    def forward(self, x):\n",
    "        ...\n",
    "        return (p3, p4, p5, p6, p7)[:self.num_layers]\n",
    "```\n",
    "приводит при скриптовании к ошибке *tuple slice indices must be integer constants*. Надо указать, что атрибут num_layers - константа и меняться не будет:\n",
    "```python\n",
    "class FPN(nn.Module):\n",
    "    num_layers: torch.jit.Final[int]\n",
    "    def __init__(self, block, num_blocks, num_layers =5):\n",
    "...        \n",
    "```\n",
    "\n",
    "* В некоторых случаях там, где раньше нормально подходил тензор, требуется в явном виде передать число:\n",
    "```python\n",
    "xx1 = x1.clamp(min=x1[i])\n",
    "```\n",
    "выдает при скриптовании ошибку *`Expected a value of type 'Optional[number]' for argument 'min' but instead found type 'Tensor'.`*. Ну, тут понятно что делать:\n",
    "```python\n",
    "xx1 = x1.clamp(min=x1[i].item())\n",
    "```\n",
    "\n",
    "\n",
    "Перечисленные выше проблемы возникают при трассировке. Именно из-за них просто скомпилировать готовые решения в TorchScript обычно не получается, и приходится или долго заниматься массажом исходного кода (если исходный код уместно редактировать), или использовать трассировку. Но и в трассировке есть свои нюансы:\n",
    "\n",
    "* В трассировке не работают конструкции вида\n",
    "```\n",
    "tensor_a.to(tensor_b.device)\n",
    "```\n",
    "Устройство, на которое загружается тензор, фиксируется в момент скриптования и в процессе выполнения не меняется. Частично справиться с этой проблемой помогает объявить тензор членом nn.Module с типом Parameter. Тогда при загрузке модели он загрузится на то устройство, которое указано в функции `torch.jit.load`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все перечисленное, конечно, создает проблемы. Но TorchScript позволяет объединить и отправить в решение как одно целое собственно модель и питоновский код, обеспечивающий пред- и постобработку. Да и время на подготовку решения к компиляции, даже несмотря на перечисленные трудности, несравнимо меньше, чем затраты за создание решения, а здесь PyTorch дает большие преимущества, так что игра стоит свеч."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/IlyaOvodov/TorchScriptTutorial/blob/master/pics/grabli.jpg?raw=true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
